{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Starter — Stage 04: Data Acquisition and Ingestion\n",
    "Name: Brandon Alcaide \n",
    "Date: 8/18/2025\n",
    "\n",
    "## Objectives\n",
    "- API ingestion with secrets in `.env`\n",
    "- Scrape a permitted public table\n",
    "- Validate and save raw data to `data/raw/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHAVANTAGE_API_KEY loaded? True\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, datetime as dt, csv, pathlib\n",
    "import yfinance as yf\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "RAW = pathlib.Path('data/raw'); RAW.mkdir(parents=True, exist_ok=True)\n",
    "load_dotenv(); print('ALPHAVANTAGE_API_KEY loaded?', bool(os.getenv('ALPHAVANTAGE_API_KEY')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers (use or modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def save_csv(df: pd.DataFrame, prefix: str, **meta):\n",
    "    mid = '_'.join([f\"{k}-{v}\" for k,v in meta.items()])\n",
    "    path = RAW / f\"{prefix}_{mid}_{ts()}.csv\"\n",
    "    df.to_csv(path, index=False)\n",
    "    print('Saved', path)\n",
    "    return path\n",
    "\n",
    "def validate(df: pd.DataFrame, required):\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    return {'missing': missing, 'shape': df.shape, 'na_total': int(df.isna().sum().sum())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 — API Pull (Required)\n",
    "Choose an endpoint (e.g., Alpha Vantage or use `yfinance` fallback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/4hrg18b5123428pg9nyyzk3c0000gn/T/ipykernel_42667/667438490.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_api = yf.download(SYMBOL, period='3mo', interval='1d').reset_index()[['Date','Close']]\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Date       Close\n",
      "Ticker                   MSFT\n",
      "0      2025-05-19  458.869995\n",
      "1      2025-05-20  458.170013\n",
      "2      2025-05-21  452.570007\n",
      "3      2025-05-22  454.859985\n",
      "4      2025-05-23  450.179993\n",
      "..            ...         ...\n",
      "58     2025-08-12  529.239990\n",
      "59     2025-08-13  520.580017\n",
      "60     2025-08-14  522.479980\n",
      "61     2025-08-15  520.169983\n",
      "62     2025-08-18  517.099976\n",
      "\n",
      "[63 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'missing': [], 'shape': (63, 2), 'na_total': 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYMBOL = \"MSFT\"\n",
    "USE_ALPHA = bool(os.getenv('ALPHAVANTAGE_API_KEY'))\n",
    "\n",
    "df_api = yf.download(SYMBOL, period='3mo', interval='1d').reset_index()[['Date','Close']]\n",
    "print(df_api)\n",
    "df_api.columns = ['date','adj_close']\n",
    "\n",
    "v_api = validate(df_api, ['date','adj_close']); v_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/raw/api_source-alpha_symbol-MSFT_20250818-205935.csv\n"
     ]
    }
   ],
   "source": [
    "_ = save_csv(df_api.sort_values('date'), prefix='api', source='alpha' if USE_ALPHA else 'yfinance', symbol=SYMBOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 — Scrape a Public Table (Required)\n",
    "Replace `SCRAPE_URL` with a permitted page containing a simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.statmuse.com/nba/player/kobe-bryant-480/career-stats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'missing': [], 'shape': (76, 24), 'na_total': 702}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRAPE_URL = 'https://www.statmuse.com/nba/player/kobe-bryant-480/career-stats'  # TODO: replace with permitted page\n",
    "print(SCRAPE_URL)\n",
    "headers = {'User-Agent':'AFE-Homework/1.0'}\n",
    "try:\n",
    "    resp = requests.get(SCRAPE_URL, headers=headers, timeout=30); resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    rows = [[c.get_text(strip=True) for c in tr.find_all(['th','td'])] for tr in soup.find_all('tr')]\n",
    "    header, *data = [r for r in rows if r]\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "except Exception as e:\n",
    "    print('Scrape failed, using inline demo table:', e)\n",
    "    html = '<table><tr><th>Ticker</th><th>Price</th></tr><tr><td>AAA</td><td>101.2</td></tr></table>'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rows = [[c.get_text(strip=True) for c in tr.find_all(['th','td'])] for tr in soup.find_all('tr')]\n",
    "    header, *data = [r for r in rows if r]\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "if 'Price' in df_scrape.columns:\n",
    "    df_scrape['Price'] = pd.to_numeric(df_scrape['Price'], errors='coerce')\n",
    "v_scrape = validate(df_scrape, list(df_scrape.columns)); v_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/raw/scrape_site-example_table-markets_20250818-211304.csv\n"
     ]
    }
   ],
   "source": [
    "_ = save_csv(df_scrape, prefix='scrape', site='example', table='markets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "- API Source: (URL/endpoint/params)\n",
    "- Scrape Source: (URL/table description)\n",
    "- Assumptions & risks: (rate limits, selector fragility, schema changes)\n",
    "- Confirm `.env` is not committed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
